{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T22:02:06.459459Z",
     "start_time": "2018-11-01T22:02:05.438042Z"
    }
   },
   "outputs": [],
   "source": [
    "import dynet_config\n",
    "dynet_config.set(random_seed=0)\n",
    "import dynet as dy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea for the training corpus: \n",
    "\n",
    "Randomly generate sets of vectors and try to learn their average.\n",
    "\n",
    "Generate 100000 (_number_of_examples_) samples of 2 (_number_of_vecors_) vectors that have a length of 10 (_vector_length_), then compute (as labels) their average. The learned weights for each vector should then be each 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T22:02:08.907206Z",
     "start_time": "2018-11-01T22:02:06.937486Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate corpus\n",
    "number_of_examples = 100000\n",
    "vector_length = 10\n",
    "number_of_vecors = 2\n",
    "\n",
    "X = np.random.rand(\n",
    "    number_of_examples,\n",
    "    number_of_vecors,\n",
    "    vector_length\n",
    ")\n",
    "\n",
    "y = np.array([np.mean(x, axis=0) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T22:05:45.280472Z",
     "start_time": "2018-11-01T22:05:45.114262Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "CwiseMultiply: For each dimension, the dim size needs to match or equal 1: [{2,10} {0}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2d199c637db5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# (this does not make sense so far, but I wasn't able to recreate the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# example I did with numpy in dynet. The dimensions didn't matched...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_dynet.pyx\u001b[0m in \u001b[0;36m_dynet.cmult\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_dynet.pyx\u001b[0m in \u001b[0;36m_dynet.cmult\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: CwiseMultiply: For each dimension, the dim size needs to match or equal 1: [{2,10} {0}]"
     ]
    }
   ],
   "source": [
    "# I have no idea why exactly the computational graph has to be renewed.\n",
    "dy.renew_cg();\n",
    "\n",
    "# The model keeps track of all the variables that we want to update.\n",
    "model = dy.ParameterCollection()\n",
    "w = model.add_parameters(0, init=1.0, name=\"weights\")\n",
    "\n",
    "# Optimizer\n",
    "trainer = dy.SimpleSGDTrainer(model, learning_rate=0.000003)\n",
    "\n",
    "for epoch in range(100):\n",
    "    cum_loss = []\n",
    "    for i in range(number_of_examples):\n",
    "        # Wrap everything in a tensor for dynet, because it needs\n",
    "        # everything to be in this format.\n",
    "        X_ = dy.inputTensor(X[i])\n",
    "        y_ = dy.inputTensor(y[i])\n",
    "        \n",
    "        # Do some calculations:\n",
    "        # (this does not make sense so far, but I wasn't able to recreate the\n",
    "        # example I did with numpy in dynet. The dimensions didn't matched...)\n",
    "        v = dy.cmult(X_, w)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = dy.squared_distance(v, y_)\n",
    "        \n",
    "        # Save the loss so that we can see if each epoch is getting better\n",
    "        cum_loss.append(loss.value())\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "        \n",
    "        # ???\n",
    "        dy.renew_cg();\n",
    "    \n",
    "    print(sum(cum_loss))\n",
    "    print(w.value())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynet",
   "language": "python",
   "name": "python2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
